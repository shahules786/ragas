{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "dc85aa4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting scikit-learn\n",
      "  Downloading scikit_learn-1.3.0-cp39-cp39-macosx_12_0_arm64.whl (9.5 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17.3 in /opt/homebrew/lib/python3.9/site-packages (from scikit-learn) (1.22.3)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-3.2.0-py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /opt/homebrew/lib/python3.9/site-packages (from scikit-learn) (1.8.0)\n",
      "Collecting joblib>=1.1.1\n",
      "  Using cached joblib-1.3.1-py3-none-any.whl (301 kB)\n",
      "Installing collected packages: threadpoolctl, joblib, scikit-learn\n",
      "\u001b[33m  DEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  DEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  DEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
      "\u001b[0mSuccessfully installed joblib-1.3.1 scikit-learn-1.3.0 threadpoolctl-3.2.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.9 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7db0b9a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/alerts/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import wikipediaapi\n",
    "\n",
    "import os\n",
    "import openai\n",
    "import json\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "openai.api_key = json.load(open(\"/Users/shahules/openai-key.json\"))['ikka']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b9266b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm(messages, **kwargs):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=kwargs.get(\"model\", \"gpt-3.5-turbo\"),\n",
    "        messages=messages,\n",
    "        temperature=kwargs.get(\"temperature\", 0),\n",
    "        top_p=kwargs.get(\"top_p\", 1),\n",
    "        frequency_penalty=kwargs.get(\"frequency_penalty\", 0.0),\n",
    "        presence_penalty=kwargs.get(\"presence_penalty\", 0.0),\n",
    "        max_tokens=kwargs.get(\"max_tokens\", 500),\n",
    "        n=kwargs.get(\"n\", 1),\n",
    "    )\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9baaee54",
   "metadata": {},
   "outputs": [],
   "source": [
    "message = [{\"role\": \"system\", \"content\": \"You're a bot that answers any given question. If you dont know the exact answer make up one.\"},\n",
    "{\"role\":\"user\", \"content\":\"What were the temperatures and snowfall amounts during the cold snap in Afghanistan in January 2023, and how many people and livestock were affected?\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c32da92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "641c1f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_wiki = wikipediaapi.Wikipedia(\n",
    "    language=\"en\", extract_format=wikipediaapi.ExtractFormat.WIKI\n",
    ")\n",
    "\n",
    "p_wiki = wiki_wiki.page(\"Black hole\")\n",
    "\n",
    "\n",
    "def get_page_section(page,chars=8000):\n",
    "    all_text = \"\"\n",
    "    p_wiki = wiki_wiki.page(page)    \n",
    "    return p_wiki.text[:chars]\n",
    "\n",
    "\n",
    "def get_cosine(page, backlinks):\n",
    "    backlinks_vec = model.encode(backlinks)\n",
    "    page_vec = model.encode([page]).reshape(1,-1)\n",
    "    norm = np.linalg.norm(backlinks_vec,axis=1)*np.linalg.norm(page_vec,axis=1)\n",
    "    cosine_sim = np.dot(backlinks_vec,page_vec.T).reshape(-1,)/norm\n",
    "    return cosine_sim\n",
    "\n",
    "def get_backlink_titles(page):\n",
    "    p_wiki = wiki_wiki.page(page) \n",
    "    backlinks =  [i.title() for i in p_wiki.backlinks if \":\" not in i.title()][:100]\n",
    "    if len(backlinks)>1:\n",
    "        c = get_cosine(page, backlinks)\n",
    "        top_indices = c.argsort()[::-1][:10]\n",
    "        return [backlinks[i] for i in top_indices if backlinks[i]!=page]\n",
    "    return []\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee43d1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Question_gen = \"\"\"\n",
    "Given a wikipedia text generate a question that can be fully answered from the text of medium difficulty with long form answer seperated by \\n\\n from the given text.\n",
    "\n",
    "Wikipedia Text:\n",
    "The Eiffel Tower is a wrought-iron lattice tower located on the Champ de Mars in Paris, France. It was named after the engineer Gustave Eiffel, whose company designed and built the structure. Erected in 1889 as the entrance arch to the 1889 World's Fair, it has become a global cultural icon of France and one of the most recognizable structures in the world. The Eiffel Tower is the tallest structure in Paris and the most-visited paid monument in the world; millions of people ascend it every year. The tower stands at a height of 324 meters (1,063 feet) and was the tallest man-made structure in the world until the completion of the Chrysler Building in New York City in 1930.\n",
    "The tower has three levels for visitors, with restaurants on the first and second levels. The third level observatory's upper platform is at 276 meters (906 feet) above the ground, the highest accessible to the public in the European Union. The tower has been featured in numerous films and TV shows, and its lighting is often modified to mark special events or holidays. Despite initial criticism from some of France's leading artists and intellectuals, the Eiffel Tower has become a global cultural icon of France and one of the most recognizable structures in the world.\n",
    "Question: What is the height of the Eiffel Tower, and how does it compare to the height of the Chrysler Building in New York City?\n",
    "\\n\\nAnswer:The height of the Eiffel Tower is 324 meters (1,063 feet). It was the tallest man-made structure in the world until the completion of the Chrysler Building in New York City in 1930. The Chrysler Building surpassed the Eiffel Tower's height and became the new tallest structure, reaching a height of 319 meters (1,046 feet) including its spire. However, it's important to note that the Eiffel Tower remains the tallest structure in Paris and still holds its title as the most-visited paid monument in the world. Despite losing its status as the tallest man-made structure globally, the Eiffel Tower's cultural significance and iconic status endure, attracting millions of visitors each year and leaving an indelible mark on the city of Paris and the world at large.\n",
    "Wikipedia Text:\\n{}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "850b2755",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "def generate_dataset(pages):\n",
    "    data = []\n",
    "    for page in tqdm(pages):\n",
    "        try:\n",
    "            text = get_page_section(page)\n",
    "            message = [{\"role\": \"user\", \"content\":Question_gen.format(text)}]\n",
    "            output = llm(message)\n",
    "            question, answer_grounded = output['choices'][0]['message']['content'].split(\"\\n\\n\")\n",
    "            message = [{\"role\": \"user\", \"content\":question}]\n",
    "            answer = llm(message)['choices'][0]['message']['content']\n",
    "            data.append({\n",
    "                \"question\":question,\n",
    "                \"grounded_answer\":answer_grounded,\n",
    "                \"answer\":answer,\n",
    "                \"context\":text,\n",
    "                \"source\":page,\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    return data\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6378ff7",
   "metadata": {},
   "source": [
    "https://en.wikipedia.org/wiki/2023#January"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1eb2ede8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/Users/shahules/belar/experimental/pages.txt\", \"r\") as file:\n",
    "    pages = file.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "608f6575",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output = llm(Question_gen.format(c.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "aebbacde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# question, answer = output['choices'][0]['message']['content'].split(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "711eca74",
   "metadata": {},
   "outputs": [],
   "source": [
    "pages = pages.split('\\n')[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "64c93114",
   "metadata": {},
   "outputs": [],
   "source": [
    "pages = [\"Volcanism on Venus\",\"Pandemic prevention\",\"Jupiter Icy Moons Explorer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9ad99e4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████| 3/3 [00:54<00:00, 18.14s/it]\n"
     ]
    }
   ],
   "source": [
    "data_sample = generate_dataset(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bf5c68fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = json.load(open(\"/Users/shahules/belar/experimental/ragas_wiki_eval.json\"))\n",
    "data.extend(data_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "49a187f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "91b678ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"ragas-eval-data.json\",'w') as file:\n",
    "    json.dump(data, file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "919d4860",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorn-khiri Sriprachuap\n",
      "Methane synthesis\n",
      "1993–94 BCFC season\n",
      "Hagawi\n",
      "Populus mexicana\n",
      "Gracie Lawrence\n",
      "Gracie Bea Lawrence\n",
      "Laura Cornelius\n",
      "A. D. Macklin\n",
      "Polyosma hirsuta\n",
      "Maltzanella\n",
      "Molina Seca\n",
      "The Life of the Party (play)\n",
      "Ramnagar Assembly constituency (disambiguation)\n",
      "Blue Angel (Park Ji-yoon album\n",
      "A.D. Macklin\n",
      "Blanca Wiethüchter López\n",
      "Frances Hughes\n",
      "Gubad Ibadoghlu\n",
      "2023 BWF World Championships – Men's doubles\n",
      "Jesús Urzagasti Aguilera\n",
      "1925 Reform Party (New Zealand) leadership election\n",
      "Ana Pinho Rodrigues\n",
      "Olympian 6\n",
      "80th Venice Film Festival\n",
      "2023 Venice Film Festival\n",
      "2023 Venice International Film Festival\n",
      "We Find the Bunyip\n",
      "C-ya-laterrrr\n",
      "Evan asano\n",
      "13th Politburo Standing Committee of the Chinese Communist Party\n",
      "Chase Blasi\n",
      "Hateful speech\n",
      "Template:WIR-280\n",
      "Archaeology in Africa\n",
      "Home (Secret Invasion)\n",
      "Anil Thadani\n",
      "Love Me a Little\n",
      "Wayne Stevens (disambiguation)\n",
      "Wayne Osborne (disambiguation)\n",
      "Wayne Hughes (disambiguation)\n",
      "Wayne Hammond (disambiguation)\n",
      "Thai Empire (disambiguation)\n",
      "Oxygen concentration (disambiguation)\n",
      "Danila Kozlov (disambiguation)\n",
      "Taivoan (disambiguation)\n",
      "Salvador Bernal (disambiguation)\n",
      "Gazo (disambiguation)\n",
      "T52 (disambiguation)\n",
      "Sergheevca (disambiguation)\n",
      "Wayne Coffey (disambiguation)\n",
      "Assistant commandant of the Marine Corps\n",
      "Lauren Anne Dickason\n",
      "Lauren Dickason\n",
      "Wikipedia talk:ANVDL\n",
      "Kira Kira, Papua New Guinea\n",
      "Pandemic of 1889-1893\n",
      "BU College of Fine Arts\n",
      "Stephen W. Gard\n",
      "HueUni\n",
      "Oscar Cerruto Collier\n",
      "Matilde Casazola Mendoza\n",
      "In a Room7 F760\n",
      "Zin2 Test5\n",
      "Kirakira (disambiguation)\n",
      "SunTec Group\n",
      "Oxygen hood\n",
      "Francisca Yu-Tsz Chang\n",
      "Athra Alliance\n",
      "Christine Tappolet\n",
      "New Media Writing Prize\n",
      "Mercedes Belzu Gorriti\n",
      "Yolanda Bedregal de Cónitzer\n",
      "Lindaura Anzoátegui de Campero\n",
      "Alcides Arguedas Díaz\n",
      "Supplemental weaving\n",
      "Albanian raid Iranian dissidents\n",
      "Brazil–Libya relations\n",
      "Siegfried Wouthuysen\n",
      "Blackbox Life Recorder 21f / In a Room7 F760\n",
      "West German cinema\n",
      "Leslie Foldy\n",
      "Skorn\n",
      "COZ (disambiguation)\n",
      "CEM (disambiguation)\n",
      "CEP (disambiguation)\n",
      "CAM (disambiguation)\n",
      "Non resistant\n",
      "Nonresistant protest\n",
      "City of Berkeley Landmark\n",
      "Functional textiles\n",
      "Ubilava\n",
      "Category talk:Quebec Cinema Awards navigational boxes\n",
      "Allison Rose\n",
      "María de las Mercedes of Orléans\n",
      "Spinning Globe (song)\n",
      "Spinning Globe\n",
      "Ina Mester\n",
      "Template:Editnotices/Page/Mick Jagger\n",
      "List of Santana band members\n",
      "Sound effect (musical instruments)\n",
      "Sound effect (plays and movies)\n",
      "Mahan (1996 film)\n",
      "2023 Spanish Election\n",
      "Table tennis at the 2023 European Games – Women's singles\n",
      "Spanish election, 2023\n",
      "Spanish election 2023\n",
      "Wenden-Thune-Harxbüttel\n",
      "Thune (Braunschweig)\n",
      "Polaris Building\n",
      "Template:Old good article table entry/doc\n",
      "Sound Affects (album)\n",
      "Pikciute\n",
      "Pikčiutė\n",
      "BIM (disambiguation)\n",
      "Universal Music Russia\n",
      "BIQ (disambiguation)\n",
      "Robin Gollan\n",
      "Murder of Nurhidayati Wartono Surata\n",
      "Golden Dragon Hotel murder\n",
      "Liam Horne\n",
      "Nurhidayati Wartono Surata\n",
      "File talk:Echo & the Bunnymen - The Stars, the Oceans & the Moon.jpg\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    get_recent_changes.py\n",
    "\n",
    "    MediaWiki API Demos\n",
    "    Demo of `RecentChanges` module: Get the three most recent changes with\n",
    "    sizes and flags\n",
    "\n",
    "    MIT License\n",
    "\"\"\"\n",
    "\n",
    "import requests\n",
    "\n",
    "S = requests.Session()\n",
    "\n",
    "URL = \"https://en.wikipedia.org/w/api.php\"\n",
    "\n",
    "PARAMS = {\n",
    "    \"format\": \"json\",\n",
    "    \"rcprop\": \"title|timestamp|tags\",\n",
    "    \"list\": \"recentchanges\",\n",
    "    \"action\": \"query\",\n",
    "    \"rclimit\": \"1000\",\n",
    "    \"rctype\":\"new\"\n",
    "}\n",
    "\n",
    "R = S.get(url=URL, params=PARAMS)\n",
    "DATA = R.json()\n",
    "\n",
    "RECENTCHANGES = DATA['query']['recentchanges']\n",
    "remove_tags = [\"User:\",\"Category:\",\"Draft\",\"User talk:\",\"Talk:\",\"Wikipedia:\",\"Template talk:\"]\n",
    "\n",
    "for rc in RECENTCHANGES:\n",
    "    title = str(rc['title'])\n",
    "    timestamp = str(rc['timestamp'])\n",
    "    if not any([x in title for x in remove_tags]) and \"2021\" not in timestamp:\n",
    "        \n",
    "        print(title)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "b074840e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = json.load(open(\"ragas-data.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "d6c20e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "evading = [\"I'm sorry\", \"as an AI language model\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "e9499102",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_regen = [item for item in data if any(x.lower() in item['answer'].lower() for x in evading)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "6ca6c290",
   "metadata": {},
   "outputs": [],
   "source": [
    "message = [{\"role\": \"system\", \"content\": \"You're a bot that answers any given question. If you dont know the exact answer make up one.\"},]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "47cf1ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in topics_regen:\n",
    "    message = [{\"role\": \"system\", \"content\": \"You're a bot that answers any given question. If you dont know the exact answer make up one.\"},]\n",
    "    message.append({\"role\":\"user\",\"content\":item['question']})\n",
    "    output = llm(message)\n",
    "    item['answer'] = output['choices'][0]['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a21cff0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 50/50 [01:23<00:00,  1.67s/it]\n"
     ]
    }
   ],
   "source": [
    "for item in tqdm(data):\n",
    "    titles = get_backlink_titles(item[\"source\"])\n",
    "    context = [get_page_section(item,chars=1000) for item in titles[:2]]\n",
    "    context.insert(0,item['context'])\n",
    "    item[\"context_retrieved\"] = context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "af204254",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"ragas_wiki_evalv1.json\",'w') as file:\n",
    "    json.dump(data, file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "67f1fe97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset json (/Users/shahules/.cache/huggingface/datasets/json/default-d425d908fb97025a/0.0.0)\n",
      "Pushing dataset shards to the dataset hub:   0%|                  | 0/1 [00:00<?, ?it/s]\n",
      "Creating parquet from Arrow format: 100%|█████████████████| 1/1 [00:00<00:00, 50.02ba/s]\u001b[A\n",
      "\n",
      "Upload 1 LFS files:   0%|                                         | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Upload 1 LFS files: 100%|█████████████████████████████████| 1/1 [00:05<00:00,  5.34s/it]\u001b[A\n",
      "Pushing dataset shards to the dataset hub: 100%|██████████| 1/1 [00:06<00:00,  6.27s/it]\n"
     ]
    }
   ],
   "source": [
    "Dataset.from_json(\"ragas-eval-data.json\").push_to_hub(\"explodinggradients/wiki-eval\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95745ce8",
   "metadata": {},
   "source": [
    "## Generate low relevancy answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "307adfa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a808a84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "irr_answer = \"\"\"\n",
    "Answer the given question partially.\n",
    "Question:{}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "15ea7908",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset None/None to /Users/shahules/.cache/huggingface/datasets/explodinggradients___parquet/explodinggradients--wiki-eval-f0df84e235efd078/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files: 100%|████████| 1/1 [00:00<00:00, 89.46it/s]\n",
      "Extracting data files: 100%|████████| 1/1 [00:00<00:00, 389.52it/s]\n",
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset parquet downloaded and prepared to /Users/shahules/.cache/huggingface/datasets/explodinggradients___parquet/explodinggradients--wiki-eval-f0df84e235efd078/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████| 1/1 [00:00<00:00, 224.16it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"explodinggradients/wiki-eval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d1fa267d",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = []\n",
    "for item in dataset['train']:\n",
    "    question = item['question']\n",
    "    message = []\n",
    "    message.append({\"role\":\"user\",\"content\":irr_answer.format(question)})\n",
    "    while True:\n",
    "        try:\n",
    "            answer = llm(message)['choices'][0]['message']['content']\n",
    "        except Exception as e:\n",
    "            continue\n",
    "        break\n",
    "    answers.append(answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b28ee072",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset[\"train\"].add_column(\"partial_answer\",answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f19512c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pushing dataset shards to the dataset hub:   0%| | 0/1 [00:00<?, ?i\n",
      "Creating parquet from Arrow format: 100%|█| 1/1 [00:00<00:00, 79.01\u001b[A\n",
      "\n",
      "Upload 1 LFS files:   0%|                    | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Upload 1 LFS files: 100%|████████████| 1/1 [00:06<00:00,  6.60s/it]\u001b[A\n",
      "Pushing dataset shards to the dataset hub: 100%|█| 1/1 [00:07<00:00\n",
      "Deleting unused files from dataset repository: 100%|█| 1/1 [00:00<0\n",
      "Updating downloaded metadata with the new split.\n"
     ]
    }
   ],
   "source": [
    "dataset.push_to_hub(\"explodinggradients/wiki-eval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "34f604e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"ragas_wiki_evalv1.json\",'w') as file:\n",
    "    json.dump(data, file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c8b429",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Alerts",
   "language": "python",
   "name": "alerts"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
