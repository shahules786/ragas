{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0174eb96",
   "metadata": {},
   "source": [
    "# Bring your own LLMs\n",
    "\n",
    "Ragas uses langchain under the hood for connecting to LLMs for metrices that require them. This means you can swap out the default LLM we use (`gpt-3.5-turbo-16k`) to use any 100s of API supported out of the box with langchain.\n",
    "\n",
    "- [Completion LLMs Supported](https://api.python.langchain.com/en/latest/api_reference.html#module-langchain.llms)\n",
    "- [Chat based LLMs Supported](https://api.python.langchain.com/en/latest/api_reference.html#module-langchain.chat_models)\n",
    "\n",
    "This guide will show you how to use another or LLM API for evaluation.\n",
    "\n",
    "> **Note**: If your looking to use Azure OpenAI for evaluation checkout [this guide](./quickstart-azure-openai.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f0f9b9",
   "metadata": {},
   "source": [
    "### Evaluating with GPT4\n",
    "\n",
    "Ragas uses gpt3.5 by default but using gpt4 for evaluation can improve the results so lets use that for the `Faithfulness` metric\n",
    "\n",
    "To start-off, we initialise the gpt4 `chat_model` from langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d96660",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure you have you OpenAI API key ready\n",
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"your-openai-key\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6906a4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "gpt4 = ChatOpenAI(model_name=\"gpt-4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1fdb48b",
   "metadata": {},
   "source": [
    "Now lets replace the `llm` used in faithfulness with `gpt4`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "307321ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.metrics import faithfulness\n",
    "\n",
    "faithfulness.llm = gpt4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1930dd49",
   "metadata": {},
   "source": [
    "That's it! faithfulness will now be using GPT-4 under the hood for evaluations.\n",
    "\n",
    "Now lets run the evaluations using the example from [quickstart](../quickstart.ipnb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62c0eadb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset fiqa (/home/jjmachan/.cache/huggingface/datasets/explodinggradients___fiqa/ragas_eval/1.0.0/3dc7b639f5b4b16509a3299a2ceb78bf5fe98ee6b5fee25e7d5e4d290c88efb8)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fb581d4057d4e70a0b70830b2f5f487",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    baseline: Dataset({\n",
       "        features: ['question', 'ground_truths', 'answer', 'contexts'],\n",
       "        num_rows: 30\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data\n",
    "from datasets import load_dataset\n",
    "\n",
    "fiqa_eval = load_dataset(\"explodinggradients/fiqa\", \"ragas_eval\")\n",
    "fiqa_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4396f6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating with [faithfulness]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████| 2/2 [22:28<00:00, 674.38s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'faithfulness': 0.7237}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate\n",
    "from ragas import evaluate\n",
    "\n",
    "result = evaluate(fiqa_eval[\"baseline\"], metrics=[faithfulness])\n",
    "\n",
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
