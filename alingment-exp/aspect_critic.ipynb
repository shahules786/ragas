{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f708066d-2e7d-46c1-81db-7d5f526c6f74",
   "metadata": {},
   "source": [
    "## LLM\n",
    "- the idea to experiment the same methods on multiple LLMs to make sure the result are LLM agnostic, ideally. Practically measure the std b/w different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7236a707-306b-403a-ba19-916c9ad82491",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8dd3cabd-8ec6-4f55-9bd3-68b38ad70f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b30b7e92-57e7-482e-b1ce-b55a259d2d40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/ragas/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "\n",
    "llm_4o = LangchainLLMWrapper(ChatOpenAI(model=\"gpt-4o\"))\n",
    "llm_4o_mini = LangchainLLMWrapper(ChatOpenAI(model=\"gpt-4o-mini\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c98778a7-e8c9-42c8-9f96-b70c30603484",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
    "\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "langchain_embeddings = LangchainEmbeddingsWrapper(embeddings=embeddings) # any langchain Embeddings instance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "279ad431-b006-464e-b9b6-5e2bcf6d71dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_aws import ChatBedrockConverse\n",
    "from langchain_aws import BedrockEmbeddings\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
    "\n",
    "config = {\n",
    "    \"credentials_profile_name\": \"default\",  # E.g \"default\"\n",
    "    \"region_name\": \"us-east-1\",  # E.g. \"us-east-1\"\n",
    "    \"llm\": \"anthropic.claude-3-haiku-20240307-v1:0\",  # E.g \"anthropic.claude-3-5-sonnet-20240620-v1:0\"\n",
    "}\n",
    "\n",
    "bedrock_llm = ChatBedrockConverse(\n",
    "    credentials_profile_name=config[\"credentials_profile_name\"],\n",
    "    region_name=config[\"region_name\"],\n",
    "    base_url=f\"https://bedrock-runtime.{config['region_name']}.amazonaws.com\",\n",
    "    model=config[\"llm\"],\n",
    ")\n",
    "\n",
    "bedrock_llm = LangchainLLMWrapper(bedrock_llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c93aed-a688-4ac9-84f5-fad2e81988bc",
   "metadata": {},
   "source": [
    "## tracing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9ae5f85-23a2-4e82-ac4c-e18c9290c5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"LANGCHAIN_PROJECT\"]= \"Alignment\"\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02887fbb-4cda-4921-8dd3-7ce72e827f5f",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9308cc73-785a-4418-b53b-4f10801f4f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.metrics._aspect_critic import AspectCriticWithReference\n",
    "from ragas import EvaluationDataset\n",
    "from datasets import load_dataset, Dataset\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11a351b5-1893-41bb-a3ff-a27e4e4ca744",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_eval_dataset(path,postive_clas=0.6, seed=42):\n",
    "    samples = []\n",
    "    np.random.seed(seed)\n",
    "    dataset = Dataset.from_json(path)\n",
    "    num = int(len(dataset)*postive_clas)\n",
    "    positive_sample_indices = np.random.randint(0,50,num).tolist()\n",
    "    negative_sample_indices = [i for i in range(len(dataset)) if i not in positive_sample_indices]\n",
    "    for i,row in enumerate(dataset):\n",
    "        dic = {\n",
    "                \"user_input\":row[\"user_input\"],\n",
    "                \"reference\": row[\"reference\"],\n",
    "                                \n",
    "            }\n",
    "        if i in positive_sample_indices:\n",
    "            dic.update(\n",
    "                {\n",
    "                    \"response\": row[\"response\"],\n",
    "                    \"target\": 1\n",
    "                }\n",
    "            )\n",
    "        else:\n",
    "             dic.update(\n",
    "                {\n",
    "                    \"response\": row[\"errored_response\"],\n",
    "                    \"target\": 0\n",
    "                }\n",
    "            )\n",
    "        samples.append(dic)\n",
    "    return Dataset.from_list(samples)\n",
    "            \n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bbdf481f-7416-4f91-ab46-6341ede26387",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = prepare_eval_dataset(\"datasets/dataset_v4.json\",postive_clas=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7198b863-3a41-4f76-ad64-ba617dee3b24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b9a48b5-1a07-461c-9091-ef1c02354e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = dataset[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "98558ed5-f4ac-421b-8d02-b848457c4a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dataset = EvaluationDataset.from_hf_dataset(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d53484-e1ab-40c7-97cd-7d645b05f229",
   "metadata": {},
   "source": [
    "## Aspect Critic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "59667893-0d0e-4e6d-aac7-261da9c64c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_examples(n=3):\n",
    "    from ragas.metrics._aspect_critic import AspectCriticInputWithReference,AspectCriticOutputWithReference\n",
    "    examples = [(\n",
    "    AspectCriticInputWithReference(\n",
    "        user_input=\"What is the main ingredient in traditional Japanese miso soup?\",\n",
    "        response=\"The main ingredient in traditional Japanese miso soup is soybeans.\",\n",
    "        reference=\"The main ingredient in traditional Japanese miso soup is miso paste, which is made from fermented soybeans.\",\n",
    "        criteria=\"Does the response accurately convey the main ingredient of the soup?\",\n",
    "    ),\n",
    "    AspectCriticOutputWithReference(\n",
    "        reason=\"The response mentions soybeans, which is part of the ingredient but does not fully capture the main ingredient, miso paste.\",\n",
    "        verdict=0,\n",
    "    ),\n",
    "),\n",
    "     (\n",
    "    AspectCriticInputWithReference(\n",
    "        user_input=\"When was the Declaration of Independence signed?\",\n",
    "        response=\"The Declaration of Independence was signed in 1776.\",\n",
    "        reference=\"The Declaration of Independence was signed on July 4, 1776.\",\n",
    "        criteria=\"Is the response factually complete, including both month and year?\",\n",
    "    ),\n",
    "    AspectCriticOutputWithReference(\n",
    "        reason=\"The response provides the correct year but omits the specific date, July 4, making it incomplete.\",\n",
    "        verdict=0,\n",
    "    ),\n",
    "),\n",
    "     (\n",
    "    AspectCriticInputWithReference(\n",
    "        user_input=\"What is the main ingredient in traditional Japanese miso soup?\",\n",
    "        response=\"The main ingredient in traditional Japanese miso soup is soybeans.\",\n",
    "        reference=\"The main ingredient in traditional Japanese miso soup is miso paste, which is made from fermented soybeans.\",\n",
    "        criteria=\"Does the response accurately convey the main ingredient of the soup?\",\n",
    "    ),\n",
    "    AspectCriticOutputWithReference(\n",
    "        reason=\"The response mentions soybeans, which is part of the ingredient but does not fully capture the main ingredient, miso paste.\",\n",
    "        verdict=0,\n",
    "    ),\n",
    ")]\n",
    "    return examples[:n]\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fb75bea8-5fcc-4439-afae-b94123b860ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "critic = AspectCriticWithReference(name=\"answer correctness\",\n",
    "                      definition=\"Given the user_input, reference and response. Is the response correct compared with the reference\",)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1e4961eb-719d-45d5-8eec-f3035b5fa861",
   "metadata": {},
   "outputs": [],
   "source": [
    "critic.single_turn_prompt.examples = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8f68a003-8a6b-40a0-ac67-74f6f0391ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "critic.llm = llm_4o\n",
    "critic.embedding_model = langchain_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "73c5e53b-6e95-4682-8356-6bfcd2e31c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eb5de705-5de0-46c8-b94e-ae9fa4472e00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|█████████| 50/50 [00:08<00:00,  6.03it/s]\n"
     ]
    }
   ],
   "source": [
    "result = evaluate(dataset=dataset,metrics=[critic])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8363f5ed-2bdc-4476-9af4-614e212bab55",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = result.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "aff33001-0e8d-4f56-b34f-3fa2a9a729e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_input</th>\n",
       "      <th>response</th>\n",
       "      <th>reference</th>\n",
       "      <th>answer correctness</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How did the invention of the wheel impact anci...</td>\n",
       "      <td># The Revolutionary Impact of the Wheel on Anc...</td>\n",
       "      <td>The invention of the wheel was a pivotal momen...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How did the discovery of fire impact early hum...</td>\n",
       "      <td># The Transformative Power of Fire in Early Hu...</td>\n",
       "      <td>The discovery of fire was a pivotal moment in ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What were the major impacts of the Agricultura...</td>\n",
       "      <td># The Transformative Impacts of the Agricultur...</td>\n",
       "      <td>The Agricultural Revolution, which began aroun...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What were the key events and consequences of t...</td>\n",
       "      <td># The Fall of Constantinople: A Turning Point ...</td>\n",
       "      <td>The Fall of Constantinople occurred on May 29,...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How did the birth of democracy in Athens shape...</td>\n",
       "      <td># The Birth of Democracy in Athens: A Revoluti...</td>\n",
       "      <td>The birth of democracy in Athens, around the 5...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          user_input  \\\n",
       "0  How did the invention of the wheel impact anci...   \n",
       "1  How did the discovery of fire impact early hum...   \n",
       "2  What were the major impacts of the Agricultura...   \n",
       "3  What were the key events and consequences of t...   \n",
       "4  How did the birth of democracy in Athens shape...   \n",
       "\n",
       "                                            response  \\\n",
       "0  # The Revolutionary Impact of the Wheel on Anc...   \n",
       "1  # The Transformative Power of Fire in Early Hu...   \n",
       "2  # The Transformative Impacts of the Agricultur...   \n",
       "3  # The Fall of Constantinople: A Turning Point ...   \n",
       "4  # The Birth of Democracy in Athens: A Revoluti...   \n",
       "\n",
       "                                           reference  answer correctness  \\\n",
       "0  The invention of the wheel was a pivotal momen...                   1   \n",
       "1  The discovery of fire was a pivotal moment in ...                   1   \n",
       "2  The Agricultural Revolution, which began aroun...                   1   \n",
       "3  The Fall of Constantinople occurred on May 29,...                   1   \n",
       "4  The birth of democracy in Athens, around the 5...                   1   \n",
       "\n",
       "   target  \n",
       "0       0  \n",
       "1       1  \n",
       "2       1  \n",
       "3       0  \n",
       "4       0  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"target\"] = y_true\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "26e9c252-59df-47cd-a6ea-7e644fcb32b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = df[\"answer correctness\"].values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37f3ac2-2a0c-494f-af1f-906ee1ca26ec",
   "metadata": {},
   "source": [
    "## evaluate the evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e5ca7bfa-5ed2-46b5-ae42-84d35c6a6ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score,precision_score,recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a831ca75-9e90-4d29-93c0-349779acbb74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 0.7096774193548387\n",
      "precision 0.55\n",
      "recall 1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"f1\",f1_score(y_true,y_pred))\n",
    "print(\"precision\",precision_score(y_true,y_pred))\n",
    "print(\"recall\",recall_score(y_true,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858363f2-fb75-4094-8fa9-66a2c6de48f8",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36c2f2e7-5c18-45a6-bbbb-aeac0f6f69ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_confusion_indices(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Function to find the indices of TP, FP, FN, and TN.\n",
    "\n",
    "    Parameters:\n",
    "    y_true (list or np.array): Ground truth binary labels (0 or 1).\n",
    "    y_pred (list or np.array): Predicted binary labels (0 or 1).\n",
    "\n",
    "    Returns:\n",
    "    dict: A dictionary containing lists of indices for TP, FP, FN, and TN.\n",
    "    \"\"\"\n",
    "    tp = [i for i, (true, pred) in enumerate(zip(y_true, y_pred)) if true == 1 and pred == 1]\n",
    "    fp = [i for i, (true, pred) in enumerate(zip(y_true, y_pred)) if true == 0 and pred == 1]\n",
    "    fn = [i for i, (true, pred) in enumerate(zip(y_true, y_pred)) if true == 1 and pred == 0]\n",
    "    tn = [i for i, (true, pred) in enumerate(zip(y_true, y_pred)) if true == 0 and pred == 0]\n",
    "\n",
    "    return {\n",
    "        'TP': tp,\n",
    "        'FP': fp,\n",
    "        'FN': fn,\n",
    "        'TN': tn\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "62fe01f5-0034-47fa-80e7-bb8449a67981",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix = get_confusion_indices(y_true,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7cda7720-2e5f-4664-9a9c-f1680d6d4ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "def serialize_for_json(data: Any) -> Any:\n",
    "    \"\"\"\n",
    "    Convert custom objects into a JSON-serializable format.\n",
    "\n",
    "    Parameters:\n",
    "    data (Any): The data to be converted, which may contain custom objects.\n",
    "\n",
    "    Returns:\n",
    "    Any: A JSON-serializable version of the input data.\n",
    "    \"\"\"\n",
    "    if isinstance(data, dict):\n",
    "        return {key: serialize_for_json(value) for key, value in data.items()}\n",
    "    elif isinstance(data, list):\n",
    "        return [serialize_for_json(item) for item in data]\n",
    "    elif hasattr(data, \"__dict__\"):\n",
    "        # Convert custom objects by serializing their attributes (assumes they use __dict__)\n",
    "        return serialize_for_json(data.__dict__)\n",
    "    else:\n",
    "        return data  # Return the data as-is if it is already JSON-serializable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ceae867d-eeec-4a9e-9782-7c01b9311457",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "samples = defaultdict(list)\n",
    "traces = result.traces\n",
    "for qdrant,indices in confusion_matrix.items():\n",
    "    for idx in indices:\n",
    "        samples[qdrant].append(serialize_for_json(traces[idx]['answer correctness']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "20a3e27b-1855-4797-a0a4-ffe336885501",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[17, 7, 1, 19]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[len(val) for val in samples.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8f4be615-391e-4989-b57b-666e68b06b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"datasets/dataset_v4_training_aspect_critic_annotated.json\",\"w\") as file:\n",
    "    json.dump(samples,file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73751ced-51a3-42aa-8412-bea1744e4c6d",
   "metadata": {},
   "source": [
    "## Embed and store samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cc95d0d7-0fbe-47be-9043-34f893d19563",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "samples = json.load(open(\"datasets/dataset_v4_training_aspect_critic_annotated.json\"))\n",
    "                     \n",
    "# embeddings.aembed_documents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "420863f3-c3ce-41bc-bb8c-1c4583810d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed(num_samples=20,seed=42):\n",
    "    tp = samples[\"TP\"]\n",
    "    tn = samples[\"TN\"]\n",
    "    fp = samples['FP']\n",
    "    fn = samples['FN']\n",
    "    all_samples = tp + tn + fp + fn\n",
    "    final_samples = []\n",
    "    for sample in all_samples:\n",
    "        if sample in tp:\n",
    "            qdrant = 'TP'\n",
    "        elif sample in fp:\n",
    "            qdrant = 'FP'\n",
    "        elif sample in tn:\n",
    "            qdrant = 'TN'\n",
    "        else:\n",
    "            qdrant = 'FN'\n",
    "        sample = list(sample.values())[0]\n",
    "        sample['qdrant'] = qdrant\n",
    "        final_samples.append(sample)\n",
    "\n",
    "    np.random.seed(seed)\n",
    "    selected_samples = list(np.random.choice(final_samples,size=num_samples))\n",
    "    embed_points = [\n",
    "        \"\\n\".join(list(data['input'].values()))\n",
    "        for data in selected_samples\n",
    "    ]\n",
    "    vectors = embeddings.embed_documents(embed_points)\n",
    "    return selected_samples,np.array(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "741c14be-ce86-42c6-90d3-0ded017aa503",
   "metadata": {},
   "outputs": [],
   "source": [
    "def json_save(data,path):\n",
    "    with open(path,\"w\") as file:\n",
    "        json.dump(data,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "74a7b607-38f5-4ed9-9db7-a7b20a49f3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_samples, vectors = embed(num_samples=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "4d770030-166e-4166-afa0-bd134d3128ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('TN', 9), ('TP', 6), ('FP', 4), ('FN', 1)]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter([sample['qdrant'] for sample in vector_samples]).most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "12dba73c-7a7b-4239-af49-d4fdbd2ace6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('indices/selected_20_indices_input_resp_ref.npy', vectors)\n",
    "json_save(vector_samples,'indices/selected_20_indices_input_resp_ref.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2d75ad9c-2ae3-4f61-b0cd-72cb52a597be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = json.load(open(\"indices/selected_20_indices.json\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f8615f8-e65f-4df6-b098-30ba60966f26",
   "metadata": {},
   "source": [
    "### Test retrival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4129eba6-bcae-4cf2-99e6-8267adec35a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.metrics._aspect_critic import AspectCriticWithReference\n",
    "critic = AspectCriticWithReference(name=\"answer correctness\",\n",
    "                      definition=\"Given the user_input, reference and response. Is the response correct compared with the reference\",)\n",
    "\n",
    "th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b4f5e92d-1f25-46e3-aa52-35118e82e0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "critic.embedding_model = langchain_embeddings\n",
    "critic.llm = llm_4o_mini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "300a4481-2f6a-437a-95f0-4cc2ade402a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas import SingleTurnSample\n",
    "dataset = Dataset.from_json(\"datasets/dataset_v4.json\")\n",
    "eval_sample = SingleTurnSample(**dataset[0])\n",
    "eval_sample.user_input = \"What were the causes and consequences of the Chernobyl Disaster?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "80f35be5-fed2-47a1-acd7-d81969b3d1b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await critic.single_turn_ascore(eval_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76dc3491-a4ce-4183-9bc5-a3bd175bc7cc",
   "metadata": {},
   "source": [
    "## prompt optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4f396ce8-df31-4b26-baea-f51d4238b786",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'reason': 'The response accurately outlines the main causes and outcomes of the Wars of the Roses, aligning well with the details provided in the reference.',\n",
       "  'verdict': 1}]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "ff3159d3-6c3c-4ef3-b573-b4180ce2b1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sampling import SingleExample,CorrectIncorrectExample,PromptFromCorrectIncorrectExamples,PromptFromCorrectExample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "4dcac3ae-cd13-4b88-a952-7a42d2543d34",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from ragas.metrics._aspect_critic import AspectCriticInputWithReference, AspectCriticOutputWithReference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "9a855c85-9c36-45e6-8c70-cfa87ab69301",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def reverse_engineer_instruction_from_correct_examples(data,llm,num_instructions=5, num_samples=10,seed=42):\n",
    "    \"\"\"\n",
    "    reverse engineer prompts using correct example\n",
    "    \"\"\"\n",
    "    generated_prompts = []\n",
    "    \n",
    "    np.random.seed(seed=seed)\n",
    "    correct_examples = [sample for sample in data if sample['qdrant'] in ['TN','TP']]\n",
    "\n",
    "    prompt = PromptFromCorrectExample()\n",
    "    for i in tqdm(range(num_instructions)):\n",
    "        input_list, output_list = [],[]\n",
    "        \n",
    "        examples  = np.random.choice(correct_examples,size=3)\n",
    "        for example in examples:\n",
    "            _ = example['input'].pop('criteria') if 'criteria' in example['input'] else None\n",
    "            input_list.append(example['input'])\n",
    "            output_list.append(example['output'][0])\n",
    "        prompt_input = SingleExample(inputs=input_list,outputs=output_list)\n",
    "        response = await prompt.generate(data=prompt_input,llm=llm)\n",
    "        generated_prompts.append(response.instruction)\n",
    "\n",
    "    return generated_prompts\n",
    "\n",
    "\n",
    "async def reverse_engineer_instruction_from_all_examples(data,llm,num_instructions=5, num_samples=10,seed=42):\n",
    "    \"\"\"\n",
    "    reverse engineer prompts using correct and incorrect examples\n",
    "    \"\"\"\n",
    "\n",
    "    def prepare_examples(examples):\n",
    "        input_list, output_list = [],[]\n",
    "        examples  = np.random.choice(examples,size=2)\n",
    "        for example in examples:\n",
    "            _ = example['input'].pop('criteria') if 'criteria' in example['input'] else None\n",
    "            input_list.append(example['input'])\n",
    "            output_list.append(example['output'][0])\n",
    "        prompt_input = SingleExample(inputs=input_list,outputs=output_list)\n",
    "        return prompt_input\n",
    "\n",
    "\n",
    "    generated_prompts = []\n",
    "    \n",
    "    np.random.seed(seed=seed)\n",
    "    correct_examples = [sample for sample in data if sample['qdrant'] in ['TN','TP']]\n",
    "    incorrect_examples = [sample for sample in data if sample['qdrant'] in ['FP','FN']]\n",
    "    prompt = PromptFromCorrectIncorrectExamples()\n",
    "    for i in tqdm(range(num_instructions)):\n",
    "        correct_input = prepare_examples(correct_examples)\n",
    "        incorrect_input = prepare_examples(incorrect_examples)\n",
    "        # return correct_input,incorrect_input\n",
    "        prompt_input = CorrectIncorrectExample(correct_examples=correct_input,incorrect_examples=incorrect_input)\n",
    "        response = await prompt.generate(data=prompt_input,llm=llm)\n",
    "        generated_prompts.append(response.instruction)\n",
    "\n",
    "    return generated_prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "7fbc886b-391a-4f4f-a811-de85e8e06e78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████| 5/5 [00:13<00:00,  2.67s/it]\n"
     ]
    }
   ],
   "source": [
    "output=await reverse_engineer_instruction_from_correct_examples(data,llm_4o_mini,num_samples=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "01d255ce-4d69-4ab6-8998-4f2c448e8c4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Provide a detailed explanation of the historical significance of the Domesday Book, including its commission by William the Conqueror, insights into 11th-century England, and its legacy as a crucial historical document. Additionally, outline the main causes and consequences of the Arab Spring, focusing on the role of authoritarian regimes, political corruption, human rights violations, economic decline, and the impact of social media, as well as the varied outcomes in different countries. Finally, discuss the causes and consequences of the Iranian Revolution of 1979, emphasizing dissatisfaction with the Shah, economic struggles, cultural disconnect, and the leadership of Ayatollah Khomeini, along with the establishment of the Islamic Republic and its impact on Middle Eastern geopolitics.',\n",
       " 'Evaluate the accuracy and completeness of the responses provided to the user inputs, comparing them against the reference texts. Assign a verdict of 1 for correct and complete responses, and 0 for those that contain factual inaccuracies or significant omissions.',\n",
       " 'Provide a detailed analysis of the causes and consequences of significant historical events, ensuring accuracy in dates and key details, while also summarizing the historical significance of important documents.',\n",
       " 'Evaluate the accuracy and completeness of the responses provided to user inquiries about historical events, comparing them to the reference material, and assign a verdict of 1 for accurate responses and 0 for inaccurate ones, while providing a reason for each verdict.',\n",
       " 'Analyze the provided user inputs and responses, and determine the correctness of the responses based on the reference information. Assign a verdict of 1 for correct responses and 0 for incorrect ones, providing a reason for each verdict.']"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "b6bd6533-0bc8-43c3-b42a-19c37178c004",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████| 5/5 [00:08<00:00,  1.74s/it]\n"
     ]
    }
   ],
   "source": [
    "output=await reverse_engineer_instruction_from_all_examples(data,llm_4o_mini,num_samples=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "3d1065f8-164d-43c2-97b3-8f94aa2bc6f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Provide a detailed explanation of the causes and consequences of a historical event, ensuring that the response aligns closely with a given reference while maintaining factual accuracy. Avoid including excessive elaboration or interpretative content that may lead to discrepancies with the reference.',\n",
       " \"Provide a detailed explanation of historical events, including their causes and consequences, while ensuring factual accuracy and relevance to the user's query. Responses should align closely with provided references, avoiding unnecessary elaboration unless it enhances understanding.\",\n",
       " 'Provide a detailed explanation of the causes and outcomes of historical events, ensuring that the response aligns closely with the reference material while maintaining clarity and coherence.',\n",
       " 'Provide a detailed explanation of historical events, including their significance, causes, and outcomes, while ensuring accuracy and alignment with provided references. Avoid unnecessary elaboration or metaphorical language unless it enhances understanding.',\n",
       " 'Provide a detailed and accurate account of historical events, including key facts, significant impacts, and relevant context, while ensuring that all dates and details are correct and aligned with established references.']"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1dded0-b4df-46d3-bfc3-14f9b447d41c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ragas",
   "language": "python",
   "name": "ragas"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
