{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38aa3c20-5a92-43f4-962a-2690588a3f01",
   "metadata": {},
   "source": [
    "See `Dataset for Metric Alignment` on Notes "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb33cb7-fce8-4ed1-9f2e-0bbeb67c10a9",
   "metadata": {},
   "source": [
    "## Set LLM to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee96fcef-b224-4f29-bcbe-d29accc01050",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "\n",
    "llm = LangchainLLMWrapper(ChatOpenAI(model=\"gpt-4o\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff4987c-f406-4d76-87ad-129e29d8a3c5",
   "metadata": {},
   "source": [
    "## Metric - Factual correctness\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f96dc55-2642-487b-8ff6-464a9ab7680b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.prompt import PydanticPrompt\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class CreateQuestion(BaseModel):\n",
    "    term: str\n",
    "    answer_length: str\n",
    "    answer_style: str\n",
    "\n",
    "class QuestionAnswer(BaseModel):\n",
    "    question: str\n",
    "    answer: str\n",
    "\n",
    "class QuestionAnswerPrompt(PydanticPrompt[CreateQuestion, QuestionAnswer]):\n",
    "    instruction: str = (\n",
    "        \"Given a seed term, generate a question that expects an answer that fits the specified \"\n",
    "        \"answer_length and answer_style.\"\n",
    "    )\n",
    "    input_model = CreateQuestion\n",
    "    output_model = QuestionAnswer\n",
    "    examples = [\n",
    "        (\n",
    "            CreateQuestion(\n",
    "                term=\"thermodynamics\",\n",
    "                answer_length=\"long (50+ words)\",\n",
    "                answer_style=\"bullet points\"\n",
    "            ),\n",
    "            QuestionAnswer(\n",
    "                question=\"What are the fundamental laws of thermodynamics?\",\n",
    "                answer=\"\"\"\n",
    "- **First Law (Conservation of Energy)**: Energy cannot be created or destroyed; it can only be transformed from one form to another.\n",
    "- **Second Law (Increase of Entropy)**: In any energy transfer, the total entropy (disorder) of an isolated system will increase over time.\n",
    "- **Third Law (Absolute Zero Entropy)**: As the temperature of a perfect crystal approaches absolute zero, its entropy approaches zero.\n",
    "- **Zeroth Law (Thermal Equilibrium)**: If two systems are in thermal equilibrium with a third system, they are in thermal equilibrium with each other.\n",
    "\"\"\"\n",
    "            )\n",
    "        ),\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9d80bd3-3e24-4dfd-b142-753e4b6f26f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "class ModifyAnswer(BaseModel):\n",
    "    original_answer: str\n",
    "    action: str  # Expected actions: \"rephrase\", \"similar_but_wrong\", \"change_response_format\"\n",
    "\n",
    "class ModifiedAnswer(BaseModel):\n",
    "    new_answer: str\n",
    "\n",
    "class ComparisonResponsePrompt(PydanticPrompt[ModifyAnswer, ModifiedAnswer]):\n",
    "    instruction: str = (\n",
    "        \"Given an answer and a comparison type, generate a new response according to the given action. \"\n",
    "        \"Ensure that the modified answer remains coherent.\"\n",
    "    )\n",
    "    input_model = ModifyAnswer\n",
    "    output_model = ModifiedAnswer\n",
    "    examples = [\n",
    "        # Example for action: rephrase\n",
    "        (\n",
    "            ModifyAnswer(\n",
    "                original_answer=\"The Eiffel Tower is located in Paris.\",\n",
    "                action=\"rephrase\"\n",
    "            ),\n",
    "            ModifiedAnswer(\n",
    "                new_answer=\"You can find the Eiffel Tower in Paris.\"\n",
    "            )\n",
    "        ),\n",
    "        # Updated Example for action: similar_but_wrong\n",
    "        (\n",
    "            ModifyAnswer(\n",
    "                original_answer=\"Plants convert sunlight into energy through photosynthesis.\",\n",
    "                action=\"similar_but_wrong\"\n",
    "            ),\n",
    "            ModifiedAnswer(\n",
    "                new_answer=\"Plants convert sunlight into energy through cellular respiration.\"\n",
    "            )\n",
    "        ),\n",
    "        # Example for action: change_response_format\n",
    "        (\n",
    "            ModifyAnswer(\n",
    "                original_answer=\"To bake a cake, you need flour, eggs, and sugar.\",\n",
    "                action=\"change_response_format\"\n",
    "            ),\n",
    "            ModifiedAnswer(\n",
    "                new_answer=\"Ingredients required:\\n- Flour\\n- Eggs\\n- Sugar\"\n",
    "            )\n",
    "        )\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f24fc9f-5c04-4bef-89aa-27e5c7644b06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13c5c824-99fb-43e8-af56-f289e1fd04fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = QuestionAnswerPrompt()\n",
    "prompt_input = CreateQuestion(term=\"gravity\", answer_length=\"long (50+ words)\", answer_style=\"narrative\")\n",
    "output = await prompt.generate(data=prompt_input, llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8151c946-b7d0-4cef-a44e-d46b08a7b180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gravity is a fundamental force that governs the motion of celestial bodies throughout the universe. It is the force of attraction between masses, and its effects can be observed on both small and large scales. On Earth, gravity gives weight to physical objects and causes them to fall towards the ground when dropped. In the vastness of space, gravity is responsible for the orbits of planets around stars, such as Earth's orbit around the Sun, and the orbits of moons around planets. It also plays a crucial role in the formation of galaxies, stars, and planetary systems. The gravitational pull of massive objects can bend light, a phenomenon known as gravitational lensing, which allows astronomers to study distant galaxies. Additionally, gravity influences the tides on Earth due to the gravitational interaction between the Earth and the Moon. Overall, gravity is a key force that shapes the structure and dynamics of the universe, affecting everything from the smallest particles to the largest cosmic structures.\n"
     ]
    }
   ],
   "source": [
    "print(output.answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "462d4988-cd6a-4345-ba16-646beb6e0678",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ComparisonResponsePrompt()\n",
    "prompt_input = ModifyAnswer(original_answer=output.answer,N=2, action=\"change_response_format\")\n",
    "output = await prompt.generate(data=prompt_input, llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4fd78450-d683-4f3e-8f5d-5760a3026d24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gravity is a fundamental force that governs the motion of celestial bodies throughout the universe. Key points include:\n",
      "\n",
      "- Force of Attraction: Gravity is the force of attraction between masses, observable on both small and large scales.\n",
      "- Effects on Earth: It gives weight to physical objects and causes them to fall towards the ground when dropped.\n",
      "- Celestial Orbits: Responsible for the orbits of planets around stars, like Earth's orbit around the Sun, and moons around planets.\n",
      "- Formation of Cosmic Structures: Plays a crucial role in the formation of galaxies, stars, and planetary systems.\n",
      "- Gravitational Lensing: The gravitational pull of massive objects can bend light, allowing astronomers to study distant galaxies.\n",
      "- Tidal Influence: Influences Earth's tides due to the gravitational interaction between the Earth and the Moon.\n",
      "\n",
      "Overall, gravity shapes the structure and dynamics of the universe, affecting everything from the smallest particles to the largest cosmic structures.\n"
     ]
    }
   ],
   "source": [
    "print(output.new_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d913125-fb31-46eb-9640-aa7798cc4c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your percentages for each answer type\n",
    "answer_length_dict = {\n",
    "    \"long (50+ words)\": 0.75,    # 40%\n",
    "    \"short (1-5 words)\": 0.05,     # 30%\n",
    "    \"medium (10-20 words)\": 0.2   # 30%\n",
    "}\n",
    "\n",
    "answer_style_list = [\"bullet point\", \"narrative\"]\n",
    "change_type_dict = {\n",
    "    \"rephrase\": 0.25, # 50%\n",
    "    \"change_response_format\":0.25,\n",
    "    \"similar_but_wrong\":0.50\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "592031db-28c4-4f45-a18c-b1b6aefbd938",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_terms():\n",
    "    # Path to the file\n",
    "    file_path = 'physics_terms.txt'\n",
    "    \n",
    "    # Reading the file into a list\n",
    "    with open(file_path, 'r') as file:\n",
    "        terms_list = [line.strip() for line in file.readlines()]\n",
    "\n",
    "    return terms_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "407b61b1-0860-437b-8eb7-96f2796f4782",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "130"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(load_terms())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac268771-8406-473c-82e9-daa51a40c3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c7e354a9-dbf2-4d08-93f7-0c719354863c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [10:57<00:00,  6.58s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "samples = []\n",
    "for term in tqdm(load_terms()[:100]):\n",
    "    sample = {}    \n",
    "    answer_type = np.random.choice(list(answer_length_dict.keys()),1,p=list(answer_length_dict.values()))[0]\n",
    "    action_type = np.random.choice(list(change_type_dict.keys()),1,p=list(change_type_dict.values()))[0]\n",
    "    answer_style = np.random.choice(answer_style_list,1)[0]\n",
    "    prompt = QuestionAnswerPrompt()\n",
    "    prompt_input = CreateQuestion(term=term, answer_length=answer_type,answer_style=answer_style)\n",
    "    output = await prompt.generate(data=prompt_input, llm=llm)\n",
    "    sample.update(\n",
    "        {\n",
    "            \"user_input\":output.question,\n",
    "            \"reference\":output.answer,\n",
    "            \"term\":term,\n",
    "            \"answer_type\":answer_type\n",
    "        }\n",
    "    )\n",
    "\n",
    "    prompt = ComparisonResponsePrompt()\n",
    "    prompt_input = ModifyAnswer(original_answer=output.answer,N=2, action=action_type)\n",
    "    output = await prompt.generate(data=prompt_input, llm=llm)\n",
    "    sample.update({\n",
    "        \"response\":output.new_answer,\n",
    "        \"action\":action_type,\n",
    "        \"target\": 1 if action_type in [\"rephrase\",\"change_response_format\"] else 0,\n",
    "    })\n",
    "    \n",
    "\n",
    "    samples.append(sample)\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c12a3f23-65b8-4e75-9e06-9f720402a8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "dataset = Dataset.from_list(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b19bc3ea-c853-4594-91af-5254bb3f176e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b0821ffa158401ebbe5f6f0d65ca77b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "158948"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.to_json(\"datasets/dataset_v2.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef73aed5-164c-494f-9133-cd87b7bd05fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset.push_to_hub(\"explodinggradients/physics_metrics_alignment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a05e35-0b74-4f8b-8bcb-b0c8949581e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b716bffa-9606-4d20-8258-fefa036fa813",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_word_histogram(input_list):\n",
    "    # Count the number of words in each string\n",
    "    word_counts = [len(sentence.split()) for sentence in input_list]\n",
    "    \n",
    "    # Plot the histogram\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(word_counts, bins=range(1, max(word_counts) + 2), edgecolor='black', align='left')\n",
    "    \n",
    "    plt.title('Histogram of Number of Words per Sentence')\n",
    "    plt.xlabel('Number of Words')\n",
    "    plt.ylabel('Frequency')\n",
    "    max_word_count = max(word_counts)\n",
    "    bins = np.linspace(1, max_word_count + 1, num=10)  # Adjust the number of bins\n",
    "    plt.xticks(bins)\n",
    "    plt.show()\n",
    "\n",
    "plot_word_histogram(dataset['reference'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e32063bd-ebc3-49e9-954f-fc2176607ea5",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c04d2f-0795-469d-95b5-b1f9e84d910d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"LANGCHAIN_PROJECT\"]= \"Alignment\"\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c1b884-8fdf-4748-a91d-28d3f09b4547",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.metrics import FactualCorrectness\n",
    "from ragas import EvaluationDataset\n",
    "from datasets import load_dataset, Dataset\n",
    "dataset = Dataset.from_json(\"datasets/dataset_v2.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f94e4f5-af6c-4f10-b90f-f34dff4c9a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe046df-2704-4403-ae98-a6b8d04db660",
   "metadata": {},
   "source": [
    "## \n",
    "Evaluating with different settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef39a888-8fa0-4944-813a-8c4bd7d32705",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas import evaluate\n",
    "import numpy as np\n",
    "\n",
    "subsample = dataset\n",
    "ragas_dataset = EvaluationDataset.from_hf_dataset(subsample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65e41f3-b229-4cca-acbe-e123ad5fc53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "def visualize(df_accuracies):\n",
    "\n",
    "    plt.plot(df_accuracies['Threshold'], df_accuracies['Accuracy'], marker='o')\n",
    "    plt.xlabel('Threshold')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Accuracy vs. Threshold')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "def calculate_accuracy_over_thresholds(y_true, y_scores, thresholds=None):\n",
    "    \"\"\"\n",
    "    Calculate accuracies over different thresholds starting from 0.5.\n",
    "\n",
    "    Parameters:\n",
    "    - y_true: array-like of shape (n_samples,), true binary targets (0 or 1)\n",
    "    - y_scores: array-like of shape (n_samples,), predicted scores/probabilities (floats between 0 and 1)\n",
    "    - thresholds: array-like of thresholds to evaluate. If None, defaults to np.arange(0.5, 1.01, 0.05)\n",
    "\n",
    "    Returns:\n",
    "    - df_results: pandas DataFrame with columns 'Threshold' and 'Accuracy'\n",
    "    \"\"\"\n",
    "    if thresholds is None:\n",
    "        thresholds = np.arange(0.5, 1.01, 0.1)\n",
    "    \n",
    "    results = []\n",
    "\n",
    "    for thresh in thresholds:\n",
    "        # Binarize the predicted scores based on the current threshold\n",
    "        y_pred = (y_scores >= thresh).astype(int)\n",
    "        \n",
    "        # Calculate accuracy\n",
    "        accuracy = (y_pred == y_true).mean()\n",
    "        \n",
    "        # Append the result to the list\n",
    "        results.append({'Threshold': thresh, 'Accuracy': accuracy})\n",
    "    \n",
    "    # Convert the results list to a pandas DataFrame\n",
    "    df_results = pd.DataFrame(results)\n",
    "    visualize(df_results)\n",
    "    return df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6738cda4-979a-440c-b484-d5c85fe9e9dc",
   "metadata": {},
   "source": [
    "### Case 1: Ragas with default prompt + (No demo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ba4a87-99ad-49fb-9feb-0b4b7e9171cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ragas_output = evaluate(ragas_dataset, metrics=[FactualCorrectness(with_examples=False)],raise_exceptions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86258ade-2f5d-44a1-aff7-43444c14a1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = np.nan_to_num(ragas_output.to_pandas()['factual_correctness'].values).tolist()\n",
    "real = subsample['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e1bb03-9cfe-4ebf-b7f3-41e49240e5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_accuracy_over_thresholds(real,pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db18757-7953-4cdd-87ef-d8fa9e405940",
   "metadata": {},
   "outputs": [],
   "source": [
    "ragas_output.to_pandas().to_csv(\"results/default_prompt_no_demo.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15af6451-23a1-417c-9e8c-bfa532c7d1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ragas_output.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3fbc74-203a-43ad-be02-b691b0a23de9",
   "metadata": {},
   "source": [
    "## Case 2 : Ragas with default prompt + Random 3 demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2120f02f-9dd7-4620-b4dd-f06a964b8e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "scorer = FactualCorrectness(with_examples=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deeee2be-eec0-4991-ad30-0d5c657c847e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ragas_output = evaluate(ragas_dataset, metrics=[scorer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9b2804-9b6d-435a-bac4-cf9ff850a7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pred = np.nan_to_num(ragas_output.to_pandas()['factual_correctness'].values).tolist()\n",
    "real = subsample['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cfea3eb-3863-4319-8c4b-bd99b364f797",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_accuracy_over_thresholds(real,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249abace-d8fd-4a97-8a1b-551210611a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439ade3c-f17f-4404-ac0f-0cf23d9f90d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6325cdae-a4b7-4336-908c-b081327b908d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ragas_output.to_pandas().to_csv(\"results/default_prompt_no_demo.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb332a1-f21f-4ee6-b13b-6e607844f333",
   "metadata": {},
   "outputs": [],
   "source": [
    "daa"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ragas",
   "language": "python",
   "name": "ragas"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
